{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Regular Expressions\nRegular expressions, dubbed RegEx, is a sequence of characters that form a search pattern. Commonly used when extracting data from text or working with string data. RegEx can be used to check if a string matches or contains a specified pattern.<br>\nPython's built in RegEx package is called `re`."},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"txt = \"Scientific Programming in Python\"\nx = re.search(\"P\",txt)\nprint(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.start(), x.end())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = re.search(\"Z\",txt)\nprint(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z=re.findall(\"P\",txt)\nprint(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z=re.findall(\"Z\",txt)\nprint(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = re.sub(\"i\",\"e\",txt,2)\nprint(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(txt)\nm = re.finditer(re.compile(\"i\"),txt)\nfor i in m:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"html = \"\"\"<li id=\"menu-item-899746\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category menu-item-899746\"><a href=\"https://techcrunch.com/mobile/\">Mobile</a></li>\n<li id=\"menu-item-899747\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-899747\"><a href=\"https://techcrunch.com/gadgets/\">Gadgets</a></li>\n<li id=\"menu-item-899748\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category menu-item-899748\"><a href=\"https://techcrunch.com/enterprise/\">Enterprise</a></li>\n<li id=\"menu-item-899749\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category menu-item-899749\"><a href=\"https://techcrunch.com/social/\">Social</a></li>\n<li id=\"menu-item-899750\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-899750\"><a href=\"https://techcrunch.com/europe/\">Europe</a></li>\n<li id=\"menu-item-901944\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-901944\"><a href=\"/asia\">Asia</a></li>\n<li id=\"menu-item-1266871\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1266871\"><a href=\"https://techcrunch.com/crunch-network/\">Crunch Network</a></li>\n<li id=\"menu-item-1210304\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1210304\"><a href=\"https://techcrunch.com/unicorn-leaderboard/\">Unicorn Leaderboard</a></li>\n<li id=\"menu-item-1242803\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1242803\"><a href=\"https://techcrunch.com/gifts/\">Gift Guides</a></li>\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anchors = re.finditer(\"<a.*>\",html)\nfor a in anchors:\n    print(a.group())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RegEx is greedy and will keep searching for a match until it reaches the end of a line. We need so be very clear on exactly which pattern we wish to match."},{"metadata":{"trusted":true},"cell_type":"code","source":"anchors = re.finditer(\"<a.*?>\",html)\nfor a in anchors:\n    print(a.group())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### here we search for a `<a` followed by any number of characters up until the first `>`"},{"metadata":{"trusted":true},"cell_type":"code","source":"menu = re.finditer('menu(-[^\\s\"]*)[\\s\"]',html)\nfor m in menu:\n    print(m.group(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"menu = re.finditer('menu(-[^\\s\"]*)-(?P<num>\\d+)',html)\nfor m in menu:\n    print(m.group(\"num\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"menu = re.finditer(r'((menu(-[^\\s\"]*)-(?P<num>\\d+)).*\\2)',html)\nfor m in menu:\n    print(m.groups())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"sea-ice.csv\") as file:\n    reader = csv.DictReader(file)\n    for i,entry in enumerate(reader):\n        print(dict(entry))\n        if (i>9):\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[]\nwith open(\"sea-ice.csv\") as file:\n    reader = csv.DictReader(file)\n    for entry in reader:\n        tmp={}\n        for key in entry.keys():\n            tmp[key.strip()]=entry[key].strip()\n        tmp['Extent']=float(tmp['Extent'])\n        data.append(tmp)\nfor d in data[0:9]:\n    print(d)\nfor d in data[-10:]:\n    print(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### We would like to create a new data set which containst the date, extent, dataset name and hemisphere for each row\nWe will start by turning \"Source Data\" into a python list. Lists are valid JSON objects, so we will use the `json.loads()` function"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = data[0][\"Source Data\"].replace(\"'\",'\"')\nprint(type(s),s)\nj = json.loads(s)\nprint(type(j), j)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parseList(s):\n    return json.loads(s.replace(\"'\",'\"'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"newData = []\nfor i,d in enumerate(data):\n    sources = parseList(d[\"Source Data\"])\n    for src in sources:\n        tmp = dict(d)\n        del tmp[\"Source Data\"]\n        tmp[\"src\"] = src\n        newData.append(tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(newData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in newData[0:9]:\n    print(d)\nfor d in newData[-10:]:\n    print(d)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will create a RegEx to extract the dataset name and date from each src"},{"metadata":{"trusted":true},"cell_type":"code","source":"pDataset = \"(nsidc\\d*)\"\npDate = \"(\\d{8})[-_]\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The datetime object"},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\n\nx = datetime.datetime.now()\n\nprint(x.year)\nprint(x.strftime(\"%A\")) #print day of week\nprint(x.strftime(\"%B\")) #print month","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The datetime constructor accepts parameters in the following order: year, month, day, hour, minute, second, microsecond*"},{"metadata":{"trusted":true},"cell_type":"code","source":"birthday = datetime.datetime(1983,9,9,17)\nprint(birthday)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We can also create a datetime object from a string by defining the format the string represents*"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = datetime.datetime.strptime(\"20000412\",\"%Y%m%d\")\nprint(dt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We can now complete our new data set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(re.search(pDate,newData[0]['src']).groups(1)[0])\nprint(re.search(pDataset,newData[0]['src']).groups(1)[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in newData:\n    src = d['src']\n    date = re.search(pDate,src).groups(1)[0]\n    dataset = re.search(pDataset,src).groups(1)[0]\n    d['Date'] = str(datetime.datetime.strptime(date,\"%Y%m%d\"))\n    d['Dataset'] = dataset\n    del d['src']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for d in newData[0:9]:\n    print(d)\nfor d in newData[-10:]:\n    print(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fieldnames = [key for key in newData[0].keys()]\nprint(fieldnames)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*We want to re-order the list so the columns will be: Date,Dataset,hemisphere,Extent*"},{"metadata":{"trusted":true},"cell_type":"code","source":"order = [2,3,1,0]\nfieldnames = [fieldnames[i] for i in order]\nprint(fieldnames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('sea-ice-fixed.csv', 'w') as csvfile:\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n    writer.writeheader()\n    for entry in newData:\n        writer.writerow(entry)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}